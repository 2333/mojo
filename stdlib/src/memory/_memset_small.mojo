# ===----------------------------------------------------------------------=== #
#
# This file is Modular Inc proprietary.
#
# ===----------------------------------------------------------------------=== #

# TODO(#19616): Enable once the elaborator error is fixed.

"""Implements the optimized memset for small sizes (<32 bytes)."""

from math import max, min

from .unsafe import DTypePointer

# This file implements the optimized memset for small sizes (<32 bytes).
#
# This approach is based on the implementation from
#    https://github.com/nadavrot/memset_benchmark
# Which is also described in
#    https://storage.googleapis.com/pub-tools-public-publication-data/pdf/4f7c3da72d557ed418828823a8e59942859d677f.pdf
#
# ----------------------
# High-level Description
# ----------------------
#
# For the best performance we want to use the widest possible register width
# for the memory access. For instance, if we want to store 19 bytes, we want
# to use vector width 16 and use two overlapping stores. To store 9 bytes, we
# would want to use two 8-byte stores.
#
# However, before we get to actually doing stores, we need to perform size
# checks to make sure that we're in the right range. I.e. we want to use 8
# bytes stores for sizes 8-16, 16 bytes stores for sizes 16-32, etc.
#
# The order in which we do the size checks significantly affects performance
# and ideally we would like to run as few checks as possible for the sizes
# that occur most often. I.e. if most of the sizes we see are 16-32, then we
# want to first check if it's within that range before we check if it's in
# 8-16 or some other range.
#
# This results in a number of different comparison "trees" that can be used to
# perform the size checks, and here we use elaborator to pick the most optimal
# one given the distribution of input data.
#
# ----------------------
# Implementation Details
# ----------------------
#
# To represent this we define interfaces for tree "layers": each layer can
# either do the store if all necessary checks have been performed or perform
# one more check and go one layer deeper.
# ===----------------------------------------------------------------------=== #


# ===-----------------------------------------------------------------------== #
# Interface for tree layers
# ===-----------------------------------------------------------------------== #
# At each layer of the tree we can choose to generate either another check, or
# stores.  Stores can only be generated when LOWER and UPPER take adjacent
# values (e.g.  4 and 8), and if that's not the case we need to generate a
# check to narrow the LOWER-UPPER range more.  Stores are generated by the
# "leaf" implementation of the layer, the checks are produced by the generic
# "layer" implementation.


# ===----------------------------------------------------------------------=== #
# Implementations for "leaf" nodes in the tree - these generators actually
# perform stores.
# ===----------------------------------------------------------------------=== #
fn overlapped_store[
    width: Int
](
    ptr: DTypePointer[DType.uint8],
    value: __mlir_type.`!pop.scalar<ui8>`,
    count: Int,
):
    """
    Perform two overlapping stores of simd_width=WIDTH in order to memset COUNT
    bytes (assuming COUNT <= WIDTH*2).
    """
    let v = SIMD[DType.uint8, width].splat(value)
    ptr.simd_store[width](v)
    ptr.simd_store[width](count - width, v)


# size == 0
@adaptive
fn layer[
    lower: Int, upper: Int
](
    ptr: DTypePointer[DType.uint8],
    value: __mlir_type.`!pop.scalar<ui8>`,
    count: Int,
):
    """
    Leaf implementation of layer: handle size 0 (do nothing).
    """
    constrained[lower == -100]()
    constrained[upper == 0]()


# 0 < size <= 4
@adaptive
fn layer[
    lower: Int, upper: Int
](
    ptr: DTypePointer[DType.uint8],
    value: __mlir_type.`!pop.scalar<ui8>`,
    count: Int,
):
    """
    Leaf implementation of layer: handle sizes from 1 to 4 by emitting two or
    four scalar stores.
    """
    constrained[lower == 0]()
    constrained[upper == 4]()

    ptr.store(0, value)
    ptr.store(count - 1, value)
    if count <= 2:
        return
    ptr.store(1, value)
    ptr.store(count - 2, value)


# 4 < size <= 8
@adaptive
fn layer[
    lower: Int, upper: Int
](
    ptr: DTypePointer[DType.uint8],
    value: __mlir_type.`!pop.scalar<ui8>`,
    count: Int,
):
    """
    Leaf implementation of layer: handle sizes from 4 to 8 by emitting two
    overlapped stores with simd_width=4.
    """
    constrained[lower == 4]()
    constrained[upper == 8]()
    overlapped_store[4](ptr, value, count)


# 8 < size <= 16
@adaptive
fn layer[
    lower: Int, upper: Int
](
    ptr: DTypePointer[DType.uint8],
    value: __mlir_type.`!pop.scalar<ui8>`,
    count: Int,
):
    """
    Leaf implementation of layer: handle sizes from 8 to 16 by emitting two
    overlapped stores with simd_width=8.
    """
    constrained[lower == 8]()
    constrained[upper == 16]()
    overlapped_store[8](ptr, value, count)


# size > 16
@adaptive
fn layer[
    lower: Int, upper: Int
](
    ptr: DTypePointer[DType.uint8],
    value: __mlir_type.`!pop.scalar<ui8>`,
    count: Int,
):
    """
    Leaf implementation of layer: handle sizes from 16 to 32 by emitting two
    overlapped stores with simd_width=16.
    """
    constrained[lower == 16]()
    constrained[upper == 100]()
    overlapped_store[16](ptr, value, count)


# ===----------------------------------------------------------------------=== #
# Layers
# ===----------------------------------------------------------------------=== #


@adaptive
fn layer[
    lower: Int, upper: Int
](
    ptr: DTypePointer[DType.uint8],
    value: __mlir_type.`!pop.scalar<ui8>`,
    count: Int,
):
    """
    The first implementation of the layer.

    We perform size comparison against parameter CUR (which we search) and then
    go into the next layer.

    We will reject CUR values if they are not between LOWER and UPPER.
    """

    # TODO: Wrap this with a nice function, e.g.
    #     alias cur : Int
    #     search4[0, 4, 8, 16 -> cur]()
    __mlir_op.`kgen.param.fork`[
        paramDecl = __mlir_attr.`#kgen<param.decl result_hidden : index>`,
        values = __mlir_attr[
            `#kgen.variadic<0, 4, 8, 16> : !kgen.variadic<index>`
        ],
    ]()
    alias cur = Int(__mlir_attr.`#kgen.param.decl.ref<"result_hidden"> : index`)

    constrained[cur > lower]()
    constrained[cur < upper]()

    if count > cur:
        layer[max(cur, lower), upper](ptr, value, count)
    else:
        layer[lower, min(cur, upper)](ptr, value, count)


@adaptive
fn layer[
    lower: Int, upper: Int
](
    ptr: DTypePointer[DType.uint8],
    value: __mlir_type.`!pop.scalar<ui8>`,
    count: Int,
):
    """
    The second implementation of the layer.

    The same as above, but the true and false branches are swapped and the
    condition in the check is inverted. The branch placements noticeably affects
    the perf, so we have to search for most optimal placement as well.
    """

    # TODO: Wrap this with a nice function, e.g.
    #     alias cur : Int
    #     search4[0, 4, 8, 16 -> cur]()
    __mlir_op.`kgen.param.fork`[
        paramDecl = __mlir_attr.`#kgen<param.decl result_hidden : index>`,
        values = __mlir_attr[
            `#kgen.variadic<0, 4, 8, 16> : !kgen.variadic<index>`
        ],
    ]()
    alias cur = Int(__mlir_attr.`#kgen.param.decl.ref<"result_hidden"> : index`)

    constrained[cur > lower]()
    constrained[cur < upper]()

    if count <= cur:
        layer[lower, min(cur, upper)](ptr, value, count)
    else:
        layer[max(cur, lower), upper](ptr, value, count)


# ===-----------------------------------------------------------------------== #
# Main interface for small memset
# ===-----------------------------------------------------------------------== #


@adaptive
fn memset_small(
    ptr: DTypePointer[DType.uint8],
    value: __mlir_type.`!pop.scalar<ui8>`,
    count: Int,
):
    """Top level generator for memset_small interface."""
    layer[-100, 100](ptr, value, count)


@adaptive
fn memset_small(
    ptr: DTypePointer[DType.uint8],
    value: __mlir_type.`!pop.scalar<ui8>`,
    count: Int,
):
    """A pre-made implementation for the case when search is disabled."""
    if count <= 4:
        if count == 0:
            return
        layer[0, 4](ptr, value, count)
        return

    if count <= 16:
        if count >= 8:
            layer[8, 16](ptr, value, count)
        else:
            layer[4, 8](ptr, value, count)
    else:
        layer[16, 100](ptr, value, count)
